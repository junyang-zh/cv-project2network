{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and download datasets\n",
    "\n",
    "# Variables\n",
    "DATASET_PATH = './data/'\n",
    "RESULT_PATH = './result_full2/'\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Loading the MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize((224, 224)),\n",
    "                                transforms.Normalize((0.5), (0.5))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(DATASET_PATH, download = True, train = True, transform = transform)\n",
    "testset = datasets.MNIST(DATASET_PATH, download = True, train = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 2, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and the optimizer\n",
    "from alexnet import AlexNet\n",
    "from optim import SGD\n",
    "\n",
    "model = AlexNet(input_channel=1, output_class=10)\n",
    "optimizer = SGD(model, lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015..\n",
      "Training pass:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2,)\n",
      "<class 'pylayer.CrossEntropyLossWithSoftmax'>\n",
      "<class 'numpy.ndarray'> (2, 10)\n",
      "<class 'pylayer.Linear'>\n",
      "<class 'numpy.ndarray'> (2, 4096)\n",
      "<class 'pylayer.ReLU'>\n",
      "<class 'numpy.ndarray'> (2, 4096)\n",
      "<class 'pylayer.Linear'>\n",
      "<class 'numpy.ndarray'> (2, 4096)\n",
      "<class 'pylayer.ReLU'>\n",
      "<class 'numpy.ndarray'> (2, 4096)\n",
      "<class 'pylayer.Linear'>\n",
      "<class 'numpy.ndarray'> (2, 6400)\n",
      "<class 'pylayer.Flatten'>\n",
      "<class 'numpy.ndarray'> (2, 256, 5, 5)\n",
      "<class 'pylayer.MaxPool2d'>\n",
      "<class 'numpy.ndarray'> (2, 256, 12, 12)\n",
      "<class 'pylayer.ReLU'>\n",
      "<class 'numpy.ndarray'> (2, 256, 12, 12)\n",
      "<class 'pylayer.Conv2d'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 442368 into shape (256,384,3,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jyz/project2network-define/mnist.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpc/home/jyz/project2network-define/mnist.ipynb#ch0000002vscode-remote?line=15'>16</a>\u001b[0m images, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy(), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpc/home/jyz/project2network-define/mnist.ipynb#ch0000002vscode-remote?line=17'>18</a>\u001b[0m prob, loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(images, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpc/home/jyz/project2network-define/mnist.ipynb#ch0000002vscode-remote?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpc/home/jyz/project2network-define/mnist.ipynb#ch0000002vscode-remote?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpc/home/jyz/project2network-define/mnist.ipynb#ch0000002vscode-remote?line=21'>22</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/project2network-define/sequential.py:35\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jyz/project2network-define/sequential.py?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(grad), grad\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='file:///home/jyz/project2network-define/sequential.py?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(l))\n\u001b[0;32m---> <a href='file:///home/jyz/project2network-define/sequential.py?line=34'>35</a>\u001b[0m bwd_ret \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39;49mbackward(grad)\n\u001b[1;32m     <a href='file:///home/jyz/project2network-define/sequential.py?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(bwd_ret, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m     <a href='file:///home/jyz/project2network-define/sequential.py?line=36'>37</a>\u001b[0m     grad \u001b[39m=\u001b[39m bwd_ret[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/project2network-define/pylayer.py:416\u001b[0m, in \u001b[0;36mConv2d.backward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jyz/project2network-define/pylayer.py?line=413'>414</a>\u001b[0m grad_output_reshaped \u001b[39m=\u001b[39m grad_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_channel,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/jyz/project2network-define/pylayer.py?line=414'>415</a>\u001b[0m grad_w \u001b[39m=\u001b[39m (grad_output_reshaped[\u001b[39mNone\u001b[39;00m,:,\u001b[39mNone\u001b[39;00m,:] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_col\u001b[39m.\u001b[39mreshape(N, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, grad_output_reshaped\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\u001b[39m.\u001b[39msum(axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum(axis \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/jyz/project2network-define/pylayer.py?line=415'>416</a>\u001b[0m grad_w \u001b[39m=\u001b[39m grad_w\u001b[39m.\u001b[39;49mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m    <a href='file:///home/jyz/project2network-define/pylayer.py?line=416'>417</a>\u001b[0m \u001b[39m#grad_w = (np.dot(grad_output_reshaped,self.input_col)).sum(axis = 1).reshape(self.weight.shape)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jyz/project2network-define/pylayer.py?line=417'>418</a>\u001b[0m w_reshape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_channel,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 442368 into shape (256,384,3,3)"
     ]
    }
   ],
   "source": [
    "# Training and evaluating process\n",
    "\n",
    "# Initiate the timer to instrument the performance\n",
    "timer_start = time.process_time_ns()\n",
    "epoch_times = [timer_start]\n",
    "\n",
    "train_losses, test_losses, accuracies = [], [], []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    print(\"Epoch: {:03d}/{:03d}..\".format(e+1, EPOCHS))\n",
    "\n",
    "    # Training pass\n",
    "    print(\"Training pass:\")\n",
    "    for data in tqdm(trainloader, total=len(trainloader)):\n",
    "        images, labels = data[0].numpy(), data[1].numpy()\n",
    "        \n",
    "        prob, loss = model.forward(images, labels)\n",
    "        model.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Testing pass\n",
    "    print(\"Validation pass:\")\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for data in tqdm(testloader, total=len(testloader)):\n",
    "        images, labels = data[0].numpy(), data[1].numpy()\n",
    "        \n",
    "        prob, loss = model.forward(images, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        ps = np.exp(prob)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        equals = (top_class == labels.view(*top_class.shape))\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(float(test_loss.cpu())/len(testloader))\n",
    "    accuracies.append(float(accuracy)/len(testloader))\n",
    "    \n",
    "    epoch_times.append(time.process_time_ns())\n",
    "    print(\"Training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "          \"Test loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)),\n",
    "          \"Cur time(ns): {}\".format(epoch_times[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(train_losses, label=\"Training loss\")\n",
    "ax.plot(test_losses, label=\"Validation loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Cross Entropy Loss\")\n",
    "ax.legend()\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(np.array(accuracies)*100, label=\"Accuracy\", color='g')\n",
    "ax2.set_ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training procedure\")\n",
    "# plt.savefig(RESULT_PATH + 'training_proc.png', dpi = 100)\n",
    "plt.show()\n",
    "\n",
    "proc_results = {\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'epoch_times': epoch_times,\n",
    "    'accuracies': accuracies,\n",
    "}\n",
    "\n",
    "print(proc_results)\n",
    "#with open(RESULT_PATH + 'torch_results.json', 'w+') as f:\n",
    "#    json.dump(proc_results, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f78116559fe3a7ec64c376b0dd016d41397fccf92ad4ec1d9222438f05fc499"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
